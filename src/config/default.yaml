General:
    comment: Sample config file
    workdir: ./
    seed: 20
    epoch: 10
    debug: False
    trainer:
        gpus: 1
        accumulate_grad_batches: 1
        progress_bar_refresh_rate: 1
        fast_dev_run: False
        num_sanity_val_steps: 0
        resume_from_checkpoint: None

dataset: 
    train_df: ./
    train_img_dir: ./
    test_df: ./
    test_img_dir: ./
    img_height: 256
    img_width: 256
    kfold: 3
dataloader:
    train: 
        batch_size: 64
        shuffle: True
        num_workers: 4
        pin_memory: False
        drop_last: True
    valid:
        batch_size: 64
        shuffle: False
        num_workers: 4
        pin_memory: False
        drop_last: False

Model:
    name: resnet34
    in_channel: 3
    out_channel: 5
    pretrained: True
    output: softmax

Optimizer:
    name: optim.AdamW
    params: 
        lr: !!python/float 1e-5 

Scheduler:
    name: optim.lr_scheduler.CosineAnnealingWarmRestarts
    params:
        T_0: 20
        eta_min: !!python/float 1e-5

loss: nn.BCEWithLogitsLoss

Augmentation:
    train:
        - name: RandomHorizontalFlip
        - name: RandomVerticalFlip
        - name: RandomAffine
          params:
            degrees: 15
            translate: !!python/object/apply:eval ['(0.1, 0.1)']
            scale: !!python/object/apply:eval ['(0.9, 1.1)']
        - name: ColorJitter
          params:
            brightness: 0.1
            contrast: 0.1
            saturation: 0.1
        - name: ConvertImageDtype
          params:
            dtype: torch.dtype
        - name: Normalize
          params:
            mean: !!python/object/apply:eval ['(0.485, 0.455, 0.406)']
            std: !!python/object/apply:eval ['(0.229, 0.224, 0.225)']
    valid:
        - name: ConvertImageDtype
          params:
            dtype: torch.dtype
        - name: Normalize
          params:
            mean: !!python/object/apply:eval ['(0.485, 0.455, 0.406)']
            std: !!python/object/apply:eval ['(0.229, 0.224, 0.225)']
        
